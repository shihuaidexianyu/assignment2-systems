# 基准测试脚本

## a
`cs336-basics/benchmarking_script.py`

## b
**设置：**
- GPU: NVIDIA GeForce RTX 4060 Laptop GPU (8 GB)
- 设备/数据类型: `cuda`、`float16`
- 批次大小: `4`
- 词汇表大小: `10000`
- 上下文长度: `128`
- 预热: `5` 步
- 测量: `10` 步
- 脚本: `cs336-basics/benchmarking_script.py`

| 规模 | d_model | d_ff | num_layers | num_heads | 前向传播均值 (ms) | 前向传播标准差 (ms) | 反向传播均值 (ms) | 反向传播标准差 (ms) |
|---|---:|---:|---:|---:|---:|---:|---:|---:|
| small | 768 | 3072 | 12 | 12 | 19.920 | 2.175 | 23.206 | 3.082 |
| medium | 1024 | 4096 | 24 | 16 | 52.056 | 5.215 | 63.543 | 3.584 |
| large | 1280 | 5120 | 36 | 20 | 77.149 | 23.159 | 131.873 | 0.581 |
| xl | 1600 | 6400 | 48 | 25 | 103.368 | 4.547 | 2239.672 | 17.477 |
| 2.7B | 2560 | 10240 | 32 | 32 | 5305.990 | 174.848 | 48300.726 | 2803.290 |

**变异性说明：**
- 大多数运行的标准差相对于均值来说属于小到中等水平。
- `large` 模型的前向传播表现出高变异性（标准差/均值 ≈ 30%），表明存在偶发的离群步骤。
- 在此硬件上，最大模型的反向传播时间非常长，但在大多数情况下相对变异性仍然较小。

## c
**设置（与 b 部分相同，仅改变了预热步数）：**
- GPU: NVIDIA GeForce RTX 4060 Laptop GPU (8 GB)
- 设备/数据类型: `cuda`、`float16`
- 批次大小: `4`
- 词汇表大小: `10000`
- 上下文长度: `128`
- 测量: `10` 步

| 规模 | 预热步数 | 前向传播均值 ± 标准差 (ms) | 反向传播均值 ± 标准差 (ms) |
|---|---:|---:|---:|
| small | 0 | 54.895 ± 103.579 | 38.504 ± 43.400 |
| small | 1 | 21.779 ± 3.050 | 27.148 ± 5.358 |
| small | 2 | 21.485 ± 2.118 | 25.143 ± 1.869 |
| small | 5 | 19.920 ± 2.175 | 23.206 ± 3.082 |
| medium | 0 | 72.413 ± 98.527 | 70.682 ± 26.522 |
| medium | 1 | 43.484 ± 5.508 | 61.311 ± 1.343 |
| medium | 2 | 45.230 ± 3.047 | 62.480 ± 1.895 |
| medium | 5 | 52.056 ± 5.215 | 63.543 ± 3.584 |
| large | 0 | 101.146 ± 108.551 | 142.805 ± 23.597 |
| large | 1 | 78.032 ± 24.142 | 137.020 ± 3.851 |
| large | 2 | 68.659 ± 18.033 | 132.744 ± 2.199 |
| large | 5 | 77.149 ± 23.159 | 131.873 ± 0.581 |
| xl | 0 | 147.227 ± 116.770 | 2838.276 ± 443.291 |
| xl | 1 | 131.035 ± 32.839 | 3608.187 ± 1453.018 |
| xl | 2 | 103.445 ± 7.546 | 2445.984 ± 487.236 |
| xl | 5 | 103.368 ± 4.547 | 2239.672 ± 17.477 |
| 2.7B | 0 | 5440.966 ± 985.767 | 52875.512 ± 5676.078 |
| 2.7B | 1 | 6559.964 ± 1949.146 | 75058.446 ± 21757.590 |
| 2.7B | 2 | 4800.032 ± 821.181 | 46554.128 ± 6760.723 |
| 2.7B | 5 | 5305.990 ± 174.848 | 48300.726 ± 2803.290 |

**观察结论：**
- 移除预热（`warmup=0`）会显著增加变异性。例如：对于 `54.895 ms` 的均值，`small` 模型的前向传播标准差达到 `103.579 ms`；对于 `72.413 ms` 的均值，`medium` 模型的前向传播标准差为 `98.527 ms`。
- `warmup=1` 或 `2` 可以改善许多配置的稳定性，但大型模型仍表现出不稳定性，尤其是反向传播（`xl`、`2.7B`）。
- 在此设置下，`warmup=5` 通常是最稳定的，能够产生更紧凑的标准差。

**原因分析：**
- 前几次迭代包含一次性开销：CUDA 上下文和内核启动、分配器池增长，以及延迟初始化/自动调优效应。
- GPU 频率/电源状态也需要从空闲状态逐步提升，因此早期的步骤可能系统性更慢或噪声更大。
- 仅用 `1-2` 步预热时，这些瞬态效应可能尚未完全消除，尤其是对于大型模型。
- 在此环境中，大型模型的内存压力较大，因此早期步骤的内存行为可能与后续稳态行为不同，使得 `1-2` 步预热仍与 `5` 步预热存在差异。
